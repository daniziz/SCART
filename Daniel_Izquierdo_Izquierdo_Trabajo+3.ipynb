{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ic4_occAAiAT"
   },
   "source": [
    "# Word Vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Eg62Pmz3o83v"
   },
   "source": [
    "En este trabajo, utilizaremos **embeddings** para resolver un problema de clasificación de texto. Los embeddings, representaciones distribuidas y vectoriales de elementos, son un concepto muy común en el mundo del deep learning. Los **word vectors** que hemos visto en clase son una representación en forma de embedding de las palabras.\n",
    "\n",
    "Para realizar este trabajo y sacarle el máximo partido, se recomienda ver los siguientes vídeos de clase:\n",
    "\n",
    "*   Clasificación de texto con Word Vectors.\n",
    "*   Análisis de overfitting con un modelo bag of words.\n",
    "*   Clasificación de texto con RNN\n",
    "\n",
    "Vamos a utilizar el dataset **\"Reuters newswire topics classification\"**, disponible desde Keras de manera similar al dataset de IMDB ([ver documentación](https://keras.io/datasets/#reuters-newswire-topics-classification)).\n",
    "\n",
    "---\n",
    "\n",
    "Se pide:\n",
    "\n",
    "Entrenar un modelo **utilizando embeddings** que consiga un **65% de accuracy en test (55% si usamos RNNs)**, mostrando el entrenamiento y el resultado final.\n",
    " \n",
    "Tenemos varias opciones para entrenar modelos con embeddings. El alumno puede explorar más de una pero es suficiente con conseguir un modelo que alcance la accuracy requerida:\n",
    "\n",
    "*   Utilizar una **media de embeddings** al estilo de lo visto en el vídeo *Clasificación de texto con Word Vectors*\n",
    "*   Utilizar una **CNN** sobre una secuencia de word vectors. Aquí necesitamos cambiar un poco la idea de convolución para actuar sobre sequencias de vectores. Keras incluye una [Convolución en 1D](https://keras.io/layers/convolutional/#conv1d) que puede ser utilizada en este caso, con un ejemplo de uso en la documentación. Una forma de hacer funcionar este esquema sería utilizar la convolución en 1D + max pooling.\n",
    "*  Utilizar una **RNN** sobre una secuencia de word vectors, al estilo de lo visto en el vídeo *Clasificación de texto con RNN*. Para este problema es un poco complicado conseguir un buen modelo con RNNs, y además es más difícil experimentar ya que las redes recurrentes son modelos lentos de entrenar. Por eso, es suficiente con alcanzar un 55% de accuracy si optamos por utilizar un modelo de este estilo. Un buen consejo es emplear una red recurrente bidireccional como se ve en el vídeo *Clasificación de texto con RNN*.\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "Dos hiperparámetros importantes a elegir en el modelo son la **longitud de las secuencias de texto** y el **tamaño del vocabulario** para los embeddings. Podéis experimentar con ambos, o utilizar los mismos que se usan en los vídeos. Nótese que, al cortar todas las secuencias para que tengan el mismo tamaño, podríamos estar perdiendo mucho texto si elegimos un tamaño de secuencia demasiado pequeño. Igualmente, si las hacemos muy largas necesitaremos más tiempo para entrenar nuestros modelos. Una buena idea consiste en explorar los datos para ver cómo suelen ser de largos los textos y encontrar un buen trade-off para el tamaño de al secuencia.\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "Los embeddings que hemos visto en los vídeos se entrenan junto al modelo.  Una técnica frecuente es inicializar estos embeddings con word-vectors pre-entrenados en un gran corpus de texto, como hemos visto en clase. Esto puede ayudar ya que nuestro modelo empieza con unos embeddings que ya encapsulan significado. Si bien no es necesario para esta práctica, podéis ver cómo usar esta técnica [en el siguiente tutorial](https://blog.keras.io/using-pre-trained-word-embeddings-in-a-keras-model.html).\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inicializamos el entorno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2ew7HTbPpCJH"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.12.0-rc2\n"
     ]
    }
   ],
   "source": [
    "## Tu código\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descargamos el dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset of 11,228 newswires from Reuters, labeled over 46 topics. As with the IMDB dataset, each wire is encoded as a sequence of word indexes (same conventions)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import reuters\n",
    "max_words=10000\n",
    "(x_train, y_train), (x_test, y_test) = reuters.load_data(path=\"reuters.npz\",\n",
    "                                                         num_words=max_words,\n",
    "                                                         skip_top=0,\n",
    "                                                         maxlen=None,\n",
    "                                                         test_split=0.2,\n",
    "                                                         seed=113,# Para shuffle\n",
    "                                                         start_char=1,\n",
    "                                                         oov_char=2,\n",
    "                                                         index_from=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training entries: 8982, labels: 8982\n",
      "Test entries: 2246, labels: 2246\n"
     ]
    }
   ],
   "source": [
    "print(\"Training entries: {}, labels: {}\".format(len(x_train), len(y_train)))\n",
    "print(\"Test entries: {}, labels: {}\".format(len(x_test), len(y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso se ha metido un valor por defecto \"test_split=0.2\" para separar el conjunto en un 80% de datos de entrenamiento y un 20% de datos de test. Como en la lección magistral, cada elemento del dataset es un vector de índices (Siendo cada índice una palabra), por lo que tenemos que descargarnos el diccionario de vectores que nos dirá a que palabra se corresponde cada índice.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Descargamos el diccionario de índices de palabras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n",
      "23568\n"
     ]
    }
   ],
   "source": [
    "word_index = reuters.get_word_index(path=\"reuters_word_index.json\")\n",
    "print(type(word_index))\n",
    "print(word_index[max(word_index)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los primeros indices están reservados para estructuras y separación de textos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The first indices are reserved\n",
    "word_index = {k:(v+3) for k,v in word_index.items()} \n",
    "word_index[\"<PAD>\"] = 0\n",
    "word_index[\"<START>\"] = 1\n",
    "word_index[\"<UNK>\"] = 2  # unknown\n",
    "word_index[\"<UNUSED>\"] = 3\n",
    "\n",
    "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comprobamos los datos descargados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 2, 8, 43, 10, 447, 5, 25, 207, 270, 5, 3095, 111, 16, 369, 186, 90, 67, 7, 89, 5, 19, 102, 6, 19, 124, 15, 90, 67, 84, 22, 482, 26, 7, 48, 4, 49, 8, 864, 39, 209, 154, 6, 151, 6, 83, 11, 15, 22, 155, 11, 15, 7, 48, 9, 4579, 1005, 504, 6, 258, 6, 272, 11, 15, 22, 134, 44, 11, 15, 16, 8, 197, 1245, 90, 67, 52, 29, 209, 30, 32, 132, 6, 109, 15, 17, 12]\n",
      "Num Classes 46\n",
      "the\n"
     ]
    }
   ],
   "source": [
    "#Imprimimos el primer valor de train\n",
    "print(x_train[0])\n",
    "\n",
    "#Imprimimos sus características\n",
    "print(\"Num Classes\", max(y_train)+1)\n",
    "\n",
    "#Imprimimos una palabra de ejemplo que se corresponda con un indice de x_train\n",
    "print(list(word_index.keys())[list(word_index.values()).index(4)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funcion decodificacion de noticias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_review(text):\n",
    "    return ' '.join([reverse_word_index.get(i, '?') for i in text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<START> the farmers home administration the u s agriculture department's farm lending arm could lose about seven billion dlrs in outstanding principal on its severely <UNK> borrowers or about one fourth of its farm loan portfolio the general accounting office gao said in remarks prepared for delivery to the senate agriculture committee brian crowley senior associate director of gao also said that a preliminary analysis of proposed changes in <UNK> financial eligibility standards indicated as many as one half of <UNK> borrowers who received new loans from the agency in 1986 would be <UNK> under the proposed system the agency has proposed evaluating <UNK> credit using a variety of financial ratios instead of relying solely on <UNK> ability senate agriculture committee chairman patrick leahy d vt <UNK> the proposed eligibility changes telling <UNK> administrator <UNK> clark at a hearing that they would mark a dramatic shift in the agency's purpose away from being farmers' lender of last resort toward becoming a big city bank but clark defended the new regulations saying the agency had a responsibility to <UNK> its 70 billion dlr loan portfolio in a <UNK> yet <UNK> manner crowley of gao <UNK> <UNK> arm said the proposed credit <UNK> system attempted to ensure that <UNK> would make loans only to borrowers who had a reasonable change of repaying their debt reuter 3\""
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode_review(x_train[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocesado de datos de train y test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como las noticias tienen longitudes distintas, hay que definir un tamaño X para todas. Las que sean mayores, se recortarán, y las que sean menores, se rellenarán con el token de padding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87\n",
      "145\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(len(x_train[0]))\n",
    "print(len(x_test[0]))\n",
    "print(word_index[\"<PAD>\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = keras.preprocessing.sequence.pad_sequences(x_train,\n",
    "                                                        value=word_index[\"<PAD>\"],\n",
    "                                                        padding='post',\n",
    "                                                        maxlen=256)\n",
    "\n",
    "x_test = keras.preprocessing.sequence.pad_sequences(x_test,\n",
    "                                                       value=word_index[\"<PAD>\"],\n",
    "                                                       padding='post',\n",
    "                                                       maxlen=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256\n",
      "256\n"
     ]
    }
   ],
   "source": [
    "print(len(x_train[0]))\n",
    "print(len(x_test[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Convert class vector to binary class matrix (for use with categorical_crossentropy)\n",
      "y_train shape: (8982, 46)\n",
      "y_test shape: (2246, 46)\n"
     ]
    }
   ],
   "source": [
    "num_classes=max(y_train)+1\n",
    "print('Convert class vector to binary class matrix '\n",
    "      '(for use with categorical_crossentropy)')\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "print('y_train shape:', y_train.shape)\n",
    "print('y_test shape:', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definimos un modelo de entrenamiento embedded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.datasets import reuters\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Embedding, GlobalAveragePooling1D\n",
    "from keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parametros del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "epochs = 40"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split de datos de entrada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val = x_train[6982:]\n",
    "x_train_partial = x_train[:6982]\n",
    "\n",
    "y_val = y_train[6982:]\n",
    "y_train_partial = y_train[:6982]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definicion del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embedding_model():\n",
    "    print('Building model...')\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(max_words, 16))\n",
    "    model.add(GlobalAveragePooling1D())\n",
    "    model.add(Dense(16, activation = \"relu\"))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(num_classes, activation = \"softmax\"))\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_7 (Embedding)      (None, None, 16)          160000    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_7 ( (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 46)                782       \n",
      "=================================================================\n",
      "Total params: 161,054\n",
      "Trainable params: 161,054\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = embedding_model()\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6982 samples, validate on 2000 samples\n",
      "Epoch 1/150\n",
      "6982/6982 [==============================] - 1s 93us/step - loss: 3.1343 - acc: 0.2557 - val_loss: 2.2914 - val_acc: 0.3465\n",
      "Epoch 2/150\n",
      "6982/6982 [==============================] - 0s 55us/step - loss: 2.4029 - acc: 0.3394 - val_loss: 2.1933 - val_acc: 0.3595\n",
      "Epoch 3/150\n",
      "6982/6982 [==============================] - 0s 54us/step - loss: 2.2800 - acc: 0.3725 - val_loss: 2.0796 - val_acc: 0.3790\n",
      "Epoch 4/150\n",
      "6982/6982 [==============================] - 0s 54us/step - loss: 2.1625 - acc: 0.3910 - val_loss: 1.9644 - val_acc: 0.3985\n",
      "Epoch 5/150\n",
      "6982/6982 [==============================] - 0s 55us/step - loss: 2.0497 - acc: 0.4242 - val_loss: 1.8661 - val_acc: 0.4555\n",
      "Epoch 6/150\n",
      "6982/6982 [==============================] - 0s 55us/step - loss: 1.9702 - acc: 0.4513 - val_loss: 1.7987 - val_acc: 0.4960\n",
      "Epoch 7/150\n",
      "6982/6982 [==============================] - 0s 55us/step - loss: 1.9053 - acc: 0.4704 - val_loss: 1.7451 - val_acc: 0.5560\n",
      "Epoch 8/150\n",
      "6982/6982 [==============================] - 0s 55us/step - loss: 1.8620 - acc: 0.4820 - val_loss: 1.7040 - val_acc: 0.5700\n",
      "Epoch 9/150\n",
      "6982/6982 [==============================] - 0s 55us/step - loss: 1.8291 - acc: 0.4898 - val_loss: 1.6763 - val_acc: 0.5810\n",
      "Epoch 10/150\n",
      "6982/6982 [==============================] - 0s 54us/step - loss: 1.7906 - acc: 0.5099 - val_loss: 1.6433 - val_acc: 0.5880\n",
      "Epoch 11/150\n",
      "6982/6982 [==============================] - 0s 54us/step - loss: 1.7560 - acc: 0.5205 - val_loss: 1.6189 - val_acc: 0.5975\n",
      "Epoch 12/150\n",
      "6982/6982 [==============================] - 0s 54us/step - loss: 1.7180 - acc: 0.5359 - val_loss: 1.5927 - val_acc: 0.6120\n",
      "Epoch 13/150\n",
      "6982/6982 [==============================] - 0s 54us/step - loss: 1.6825 - acc: 0.5487 - val_loss: 1.5682 - val_acc: 0.6180\n",
      "Epoch 14/150\n",
      "6982/6982 [==============================] - 0s 55us/step - loss: 1.6521 - acc: 0.5602 - val_loss: 1.5379 - val_acc: 0.6215\n",
      "Epoch 15/150\n",
      "6982/6982 [==============================] - 0s 55us/step - loss: 1.6249 - acc: 0.5698 - val_loss: 1.5215 - val_acc: 0.6305\n",
      "Epoch 16/150\n",
      "6982/6982 [==============================] - 0s 54us/step - loss: 1.5923 - acc: 0.5832 - val_loss: 1.5018 - val_acc: 0.6335\n",
      "Epoch 17/150\n",
      "6982/6982 [==============================] - 0s 55us/step - loss: 1.5653 - acc: 0.5902 - val_loss: 1.4861 - val_acc: 0.6385\n",
      "Epoch 18/150\n",
      "6982/6982 [==============================] - 0s 55us/step - loss: 1.5415 - acc: 0.5983 - val_loss: 1.4770 - val_acc: 0.6375\n",
      "Epoch 19/150\n",
      "6982/6982 [==============================] - 0s 55us/step - loss: 1.5304 - acc: 0.5968 - val_loss: 1.4652 - val_acc: 0.6425\n",
      "Epoch 20/150\n",
      "6982/6982 [==============================] - 0s 55us/step - loss: 1.5075 - acc: 0.6068 - val_loss: 1.4511 - val_acc: 0.6470\n",
      "Epoch 21/150\n",
      "6982/6982 [==============================] - 0s 55us/step - loss: 1.4949 - acc: 0.6051 - val_loss: 1.4426 - val_acc: 0.6410\n",
      "Epoch 22/150\n",
      "6982/6982 [==============================] - 0s 54us/step - loss: 1.4699 - acc: 0.6186 - val_loss: 1.4281 - val_acc: 0.6525\n",
      "Epoch 23/150\n",
      "6982/6982 [==============================] - 0s 55us/step - loss: 1.4520 - acc: 0.6207 - val_loss: 1.4212 - val_acc: 0.6630\n",
      "Epoch 24/150\n",
      "6982/6982 [==============================] - 0s 55us/step - loss: 1.4159 - acc: 0.6312 - val_loss: 1.3976 - val_acc: 0.6675\n",
      "Epoch 25/150\n",
      "6982/6982 [==============================] - 0s 55us/step - loss: 1.4022 - acc: 0.6308 - val_loss: 1.3925 - val_acc: 0.6700\n",
      "Epoch 26/150\n",
      "6982/6982 [==============================] - 0s 54us/step - loss: 1.3674 - acc: 0.6422 - val_loss: 1.3790 - val_acc: 0.6805\n",
      "Epoch 27/150\n",
      "6982/6982 [==============================] - 0s 55us/step - loss: 1.3511 - acc: 0.6458 - val_loss: 1.3655 - val_acc: 0.6805\n",
      "Epoch 28/150\n",
      "6982/6982 [==============================] - 0s 55us/step - loss: 1.3251 - acc: 0.6507 - val_loss: 1.3567 - val_acc: 0.6790\n",
      "Epoch 29/150\n",
      "6982/6982 [==============================] - 0s 55us/step - loss: 1.3251 - acc: 0.6524 - val_loss: 1.3500 - val_acc: 0.6830\n",
      "Epoch 30/150\n",
      "6982/6982 [==============================] - 0s 55us/step - loss: 1.3066 - acc: 0.6561 - val_loss: 1.3496 - val_acc: 0.6810\n",
      "Epoch 31/150\n",
      "6982/6982 [==============================] - 0s 55us/step - loss: 1.2904 - acc: 0.6547 - val_loss: 1.3403 - val_acc: 0.6850\n",
      "Epoch 32/150\n",
      "6982/6982 [==============================] - 0s 55us/step - loss: 1.2634 - acc: 0.6628 - val_loss: 1.3339 - val_acc: 0.6825\n",
      "Epoch 33/150\n",
      "6982/6982 [==============================] - 0s 55us/step - loss: 1.2560 - acc: 0.6663 - val_loss: 1.3347 - val_acc: 0.6845\n",
      "Epoch 34/150\n",
      "6982/6982 [==============================] - 0s 55us/step - loss: 1.2329 - acc: 0.6673 - val_loss: 1.3341 - val_acc: 0.6880\n",
      "Epoch 35/150\n",
      "6982/6982 [==============================] - 0s 55us/step - loss: 1.2143 - acc: 0.6757 - val_loss: 1.3262 - val_acc: 0.6960\n",
      "Epoch 36/150\n",
      "6982/6982 [==============================] - 0s 55us/step - loss: 1.2060 - acc: 0.6743 - val_loss: 1.3337 - val_acc: 0.6910\n",
      "Epoch 37/150\n",
      "6982/6982 [==============================] - 0s 55us/step - loss: 1.1969 - acc: 0.6780 - val_loss: 1.3248 - val_acc: 0.6955\n",
      "Epoch 38/150\n",
      "6982/6982 [==============================] - 0s 55us/step - loss: 1.1898 - acc: 0.6805 - val_loss: 1.3195 - val_acc: 0.6990\n",
      "Epoch 39/150\n",
      "6982/6982 [==============================] - 0s 55us/step - loss: 1.1737 - acc: 0.6895 - val_loss: 1.3197 - val_acc: 0.6985\n",
      "Epoch 40/150\n",
      "6982/6982 [==============================] - 0s 55us/step - loss: 1.1439 - acc: 0.6888 - val_loss: 1.3317 - val_acc: 0.6985\n",
      "Epoch 41/150\n",
      "6982/6982 [==============================] - 0s 55us/step - loss: 1.1422 - acc: 0.6889 - val_loss: 1.3239 - val_acc: 0.7050\n",
      "Epoch 42/150\n",
      "6982/6982 [==============================] - 0s 55us/step - loss: 1.1349 - acc: 0.6924 - val_loss: 1.3256 - val_acc: 0.7045\n",
      "Epoch 43/150\n",
      "6982/6982 [==============================] - 0s 55us/step - loss: 1.1142 - acc: 0.6964 - val_loss: 1.3327 - val_acc: 0.7030\n",
      "Epoch 44/150\n",
      "6982/6982 [==============================] - 0s 55us/step - loss: 1.1030 - acc: 0.6969 - val_loss: 1.3372 - val_acc: 0.7065\n",
      "Epoch 45/150\n",
      "6982/6982 [==============================] - 0s 55us/step - loss: 1.0911 - acc: 0.6998 - val_loss: 1.3360 - val_acc: 0.7065\n",
      "Epoch 46/150\n",
      "6982/6982 [==============================] - 0s 55us/step - loss: 1.0915 - acc: 0.7038 - val_loss: 1.3419 - val_acc: 0.7070\n",
      "Epoch 47/150\n",
      "6982/6982 [==============================] - 0s 56us/step - loss: 1.0771 - acc: 0.7014 - val_loss: 1.3518 - val_acc: 0.7050\n",
      "Epoch 48/150\n",
      "6982/6982 [==============================] - 0s 54us/step - loss: 1.0619 - acc: 0.7065 - val_loss: 1.3422 - val_acc: 0.7090\n",
      "Epoch 49/150\n",
      "6982/6982 [==============================] - 0s 55us/step - loss: 1.0531 - acc: 0.7103 - val_loss: 1.3429 - val_acc: 0.7070\n",
      "Epoch 50/150\n",
      "6982/6982 [==============================] - 0s 55us/step - loss: 1.0490 - acc: 0.7052 - val_loss: 1.3564 - val_acc: 0.7100\n",
      "Epoch 51/150\n",
      "6982/6982 [==============================] - 0s 54us/step - loss: 1.0493 - acc: 0.7095 - val_loss: 1.3660 - val_acc: 0.7085\n",
      "Epoch 52/150\n",
      "6982/6982 [==============================] - 0s 55us/step - loss: 1.0374 - acc: 0.7067 - val_loss: 1.3575 - val_acc: 0.7125\n",
      "Epoch 53/150\n",
      "6982/6982 [==============================] - 0s 55us/step - loss: 1.0260 - acc: 0.7128 - val_loss: 1.3878 - val_acc: 0.7075\n",
      "Epoch 54/150\n",
      "6982/6982 [==============================] - 0s 54us/step - loss: 1.0106 - acc: 0.7147 - val_loss: 1.3746 - val_acc: 0.7110\n",
      "Epoch 55/150\n",
      "6982/6982 [==============================] - 0s 54us/step - loss: 0.9982 - acc: 0.7151 - val_loss: 1.3826 - val_acc: 0.7125\n",
      "Epoch 56/150\n",
      "6982/6982 [==============================] - 0s 55us/step - loss: 0.9921 - acc: 0.7157 - val_loss: 1.3815 - val_acc: 0.7125\n",
      "Epoch 57/150\n",
      "6982/6982 [==============================] - 0s 54us/step - loss: 0.9853 - acc: 0.7259 - val_loss: 1.4056 - val_acc: 0.7110\n",
      "Epoch 58/150\n",
      "6982/6982 [==============================] - 0s 54us/step - loss: 0.9832 - acc: 0.7188 - val_loss: 1.4077 - val_acc: 0.7105\n",
      "Epoch 59/150\n",
      "6982/6982 [==============================] - 0s 55us/step - loss: 0.9763 - acc: 0.7237 - val_loss: 1.3994 - val_acc: 0.7095\n",
      "Epoch 60/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6982/6982 [==============================] - 0s 54us/step - loss: 0.9635 - acc: 0.7229 - val_loss: 1.4442 - val_acc: 0.7085\n",
      "Epoch 61/150\n",
      "6982/6982 [==============================] - 0s 54us/step - loss: 0.9661 - acc: 0.7262 - val_loss: 1.4381 - val_acc: 0.7105\n",
      "Epoch 62/150\n",
      "6982/6982 [==============================] - 0s 53us/step - loss: 0.9550 - acc: 0.7226 - val_loss: 1.4605 - val_acc: 0.7075\n",
      "Epoch 63/150\n",
      "6982/6982 [==============================] - 0s 53us/step - loss: 0.9368 - acc: 0.7274 - val_loss: 1.4482 - val_acc: 0.7040\n",
      "Epoch 64/150\n",
      "6982/6982 [==============================] - 0s 54us/step - loss: 0.9349 - acc: 0.7300 - val_loss: 1.4206 - val_acc: 0.7135\n",
      "Epoch 65/150\n",
      "6982/6982 [==============================] - 0s 53us/step - loss: 0.9237 - acc: 0.7279 - val_loss: 1.4345 - val_acc: 0.7120\n",
      "Epoch 66/150\n",
      "6982/6982 [==============================] - 0s 53us/step - loss: 0.9267 - acc: 0.7312 - val_loss: 1.4396 - val_acc: 0.7110\n",
      "Epoch 67/150\n",
      "6982/6982 [==============================] - 0s 54us/step - loss: 0.9108 - acc: 0.7296 - val_loss: 1.4751 - val_acc: 0.7115\n",
      "Epoch 68/150\n",
      "6982/6982 [==============================] - 0s 53us/step - loss: 0.9061 - acc: 0.7453 - val_loss: 1.4708 - val_acc: 0.7100\n",
      "Epoch 69/150\n",
      "6982/6982 [==============================] - 0s 54us/step - loss: 0.9046 - acc: 0.7366 - val_loss: 1.4907 - val_acc: 0.7090\n",
      "Epoch 70/150\n",
      "6982/6982 [==============================] - 0s 54us/step - loss: 0.8852 - acc: 0.7392 - val_loss: 1.5163 - val_acc: 0.7045\n",
      "Epoch 71/150\n",
      "6982/6982 [==============================] - 0s 54us/step - loss: 0.8887 - acc: 0.7399 - val_loss: 1.4936 - val_acc: 0.7095\n",
      "Epoch 72/150\n",
      "6982/6982 [==============================] - 0s 54us/step - loss: 0.8808 - acc: 0.7429 - val_loss: 1.5148 - val_acc: 0.7135\n",
      "Epoch 73/150\n",
      "6982/6982 [==============================] - 0s 54us/step - loss: 0.8778 - acc: 0.7405 - val_loss: 1.5552 - val_acc: 0.7090\n",
      "Epoch 74/150\n",
      "6982/6982 [==============================] - 0s 58us/step - loss: 0.8643 - acc: 0.7385 - val_loss: 1.5554 - val_acc: 0.7110\n",
      "Epoch 75/150\n",
      "6982/6982 [==============================] - 0s 59us/step - loss: 0.8627 - acc: 0.7462 - val_loss: 1.5583 - val_acc: 0.7125\n",
      "Epoch 76/150\n",
      "6982/6982 [==============================] - 0s 60us/step - loss: 0.8743 - acc: 0.7396 - val_loss: 1.5395 - val_acc: 0.7155\n",
      "Epoch 77/150\n",
      "6982/6982 [==============================] - 0s 58us/step - loss: 0.8637 - acc: 0.7413 - val_loss: 1.5712 - val_acc: 0.7115\n",
      "Epoch 78/150\n",
      "6982/6982 [==============================] - 0s 58us/step - loss: 0.8470 - acc: 0.7476 - val_loss: 1.5739 - val_acc: 0.7125\n",
      "Epoch 79/150\n",
      "6982/6982 [==============================] - 0s 58us/step - loss: 0.8584 - acc: 0.7465 - val_loss: 1.6072 - val_acc: 0.7125\n",
      "Epoch 80/150\n",
      "6982/6982 [==============================] - 0s 58us/step - loss: 0.8572 - acc: 0.7426 - val_loss: 1.5942 - val_acc: 0.7165\n",
      "Epoch 81/150\n",
      "6982/6982 [==============================] - 0s 57us/step - loss: 0.8407 - acc: 0.7478 - val_loss: 1.5996 - val_acc: 0.7120\n",
      "Epoch 82/150\n",
      "6982/6982 [==============================] - 0s 57us/step - loss: 0.8321 - acc: 0.7484 - val_loss: 1.6290 - val_acc: 0.7130\n",
      "Epoch 83/150\n",
      "6982/6982 [==============================] - 0s 58us/step - loss: 0.8166 - acc: 0.7547 - val_loss: 1.6233 - val_acc: 0.7160\n",
      "Epoch 84/150\n",
      "6982/6982 [==============================] - 0s 59us/step - loss: 0.8128 - acc: 0.7561 - val_loss: 1.6630 - val_acc: 0.7125\n",
      "Epoch 85/150\n",
      "6982/6982 [==============================] - 0s 57us/step - loss: 0.8279 - acc: 0.7429 - val_loss: 1.6470 - val_acc: 0.7165\n",
      "Epoch 86/150\n",
      "6982/6982 [==============================] - 0s 55us/step - loss: 0.8245 - acc: 0.7461 - val_loss: 1.6388 - val_acc: 0.7175\n",
      "Epoch 87/150\n",
      "6982/6982 [==============================] - 0s 59us/step - loss: 0.8154 - acc: 0.7488 - val_loss: 1.6628 - val_acc: 0.7155\n",
      "Epoch 88/150\n",
      "6982/6982 [==============================] - 0s 54us/step - loss: 0.8193 - acc: 0.7471 - val_loss: 1.6763 - val_acc: 0.7155\n",
      "Epoch 89/150\n",
      "6982/6982 [==============================] - 0s 54us/step - loss: 0.8093 - acc: 0.7544 - val_loss: 1.6764 - val_acc: 0.7170\n",
      "Epoch 90/150\n",
      "6982/6982 [==============================] - 0s 54us/step - loss: 0.8100 - acc: 0.7516 - val_loss: 1.7306 - val_acc: 0.7140\n",
      "Epoch 91/150\n",
      "6982/6982 [==============================] - 0s 59us/step - loss: 0.7960 - acc: 0.7571 - val_loss: 1.7504 - val_acc: 0.7140\n",
      "Epoch 92/150\n",
      "6982/6982 [==============================] - 0s 58us/step - loss: 0.8068 - acc: 0.7494 - val_loss: 1.7008 - val_acc: 0.7150\n",
      "Epoch 93/150\n",
      "6982/6982 [==============================] - 0s 56us/step - loss: 0.7896 - acc: 0.7534 - val_loss: 1.6974 - val_acc: 0.7185\n",
      "Epoch 94/150\n",
      "6982/6982 [==============================] - 0s 55us/step - loss: 0.7894 - acc: 0.7598 - val_loss: 1.7517 - val_acc: 0.7140\n",
      "Epoch 95/150\n",
      "6982/6982 [==============================] - 0s 59us/step - loss: 0.7820 - acc: 0.7605 - val_loss: 1.7563 - val_acc: 0.7160\n",
      "Epoch 96/150\n",
      "6982/6982 [==============================] - 0s 57us/step - loss: 0.7870 - acc: 0.7539 - val_loss: 1.7289 - val_acc: 0.7180\n",
      "Epoch 97/150\n",
      "6982/6982 [==============================] - 0s 56us/step - loss: 0.7663 - acc: 0.7612 - val_loss: 1.7468 - val_acc: 0.7140\n",
      "Epoch 98/150\n",
      "6982/6982 [==============================] - 0s 58us/step - loss: 0.7678 - acc: 0.7638 - val_loss: 1.8045 - val_acc: 0.7125\n",
      "Epoch 99/150\n",
      "6982/6982 [==============================] - 0s 59us/step - loss: 0.7693 - acc: 0.7600 - val_loss: 1.7716 - val_acc: 0.7150\n",
      "Epoch 100/150\n",
      "6982/6982 [==============================] - 0s 55us/step - loss: 0.7626 - acc: 0.7628 - val_loss: 1.7659 - val_acc: 0.7155\n",
      "Epoch 101/150\n",
      "6982/6982 [==============================] - 0s 60us/step - loss: 0.7452 - acc: 0.7645 - val_loss: 1.7866 - val_acc: 0.7160\n",
      "Epoch 102/150\n",
      "6982/6982 [==============================] - 0s 56us/step - loss: 0.7630 - acc: 0.7631 - val_loss: 1.8006 - val_acc: 0.7155\n",
      "Epoch 103/150\n",
      "6982/6982 [==============================] - 0s 57us/step - loss: 0.7597 - acc: 0.7561 - val_loss: 1.7848 - val_acc: 0.7140\n",
      "Epoch 104/150\n",
      "6982/6982 [==============================] - 0s 59us/step - loss: 0.7596 - acc: 0.7654 - val_loss: 1.8018 - val_acc: 0.7150\n",
      "Epoch 105/150\n",
      "6982/6982 [==============================] - 0s 58us/step - loss: 0.7497 - acc: 0.7667 - val_loss: 1.8493 - val_acc: 0.7150\n",
      "Epoch 106/150\n",
      "6982/6982 [==============================] - 0s 59us/step - loss: 0.7321 - acc: 0.7697 - val_loss: 1.8583 - val_acc: 0.7140\n",
      "Epoch 107/150\n",
      "6982/6982 [==============================] - 0s 58us/step - loss: 0.7397 - acc: 0.7673 - val_loss: 1.8656 - val_acc: 0.7135\n",
      "Epoch 108/150\n",
      "6982/6982 [==============================] - 0s 58us/step - loss: 0.7354 - acc: 0.7648 - val_loss: 1.8805 - val_acc: 0.7130\n",
      "Epoch 109/150\n",
      "6982/6982 [==============================] - 0s 55us/step - loss: 0.7430 - acc: 0.7612 - val_loss: 1.8704 - val_acc: 0.7125\n",
      "Epoch 110/150\n",
      "6982/6982 [==============================] - 0s 55us/step - loss: 0.7468 - acc: 0.7678 - val_loss: 1.8718 - val_acc: 0.7145\n",
      "Epoch 111/150\n",
      "6982/6982 [==============================] - 0s 60us/step - loss: 0.7148 - acc: 0.7737 - val_loss: 1.8599 - val_acc: 0.7150\n",
      "Epoch 112/150\n",
      "6982/6982 [==============================] - 0s 59us/step - loss: 0.7200 - acc: 0.7683 - val_loss: 1.8872 - val_acc: 0.7160\n",
      "Epoch 113/150\n",
      "6982/6982 [==============================] - 0s 58us/step - loss: 0.7166 - acc: 0.7761 - val_loss: 1.8891 - val_acc: 0.7145\n",
      "Epoch 114/150\n",
      "6982/6982 [==============================] - 0s 57us/step - loss: 0.7248 - acc: 0.7738 - val_loss: 1.8915 - val_acc: 0.7200\n",
      "Epoch 115/150\n",
      "6982/6982 [==============================] - 0s 57us/step - loss: 0.7290 - acc: 0.7716 - val_loss: 1.9226 - val_acc: 0.7175\n",
      "Epoch 116/150\n",
      "6982/6982 [==============================] - 0s 59us/step - loss: 0.7147 - acc: 0.7747 - val_loss: 1.9243 - val_acc: 0.7190\n",
      "Epoch 117/150\n",
      "6982/6982 [==============================] - 0s 58us/step - loss: 0.7199 - acc: 0.7720 - val_loss: 1.9172 - val_acc: 0.7180\n",
      "Epoch 118/150\n",
      "6982/6982 [==============================] - 0s 58us/step - loss: 0.7135 - acc: 0.7750 - val_loss: 1.9359 - val_acc: 0.7145\n",
      "Epoch 119/150\n",
      "6982/6982 [==============================] - 0s 56us/step - loss: 0.7245 - acc: 0.7724 - val_loss: 1.9258 - val_acc: 0.7170\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 120/150\n",
      "6982/6982 [==============================] - 0s 59us/step - loss: 0.7055 - acc: 0.7731 - val_loss: 1.9324 - val_acc: 0.7135\n",
      "Epoch 121/150\n",
      "6982/6982 [==============================] - 0s 59us/step - loss: 0.7190 - acc: 0.7789 - val_loss: 1.9468 - val_acc: 0.7145\n",
      "Epoch 122/150\n",
      "6982/6982 [==============================] - 0s 58us/step - loss: 0.6984 - acc: 0.7819 - val_loss: 1.9739 - val_acc: 0.7125\n",
      "Epoch 123/150\n",
      "6982/6982 [==============================] - 0s 54us/step - loss: 0.7120 - acc: 0.7753 - val_loss: 1.9538 - val_acc: 0.7195\n",
      "Epoch 124/150\n",
      "6982/6982 [==============================] - 0s 58us/step - loss: 0.6879 - acc: 0.7804 - val_loss: 1.9820 - val_acc: 0.7170\n",
      "Epoch 125/150\n",
      "6982/6982 [==============================] - 0s 58us/step - loss: 0.6954 - acc: 0.7794 - val_loss: 1.9542 - val_acc: 0.7155\n",
      "Epoch 126/150\n",
      "6982/6982 [==============================] - 0s 54us/step - loss: 0.7072 - acc: 0.7736 - val_loss: 1.9713 - val_acc: 0.7110\n",
      "Epoch 127/150\n",
      "6982/6982 [==============================] - 0s 55us/step - loss: 0.6919 - acc: 0.7799 - val_loss: 1.9945 - val_acc: 0.7155\n",
      "Epoch 128/150\n",
      "6982/6982 [==============================] - 0s 57us/step - loss: 0.6812 - acc: 0.7842 - val_loss: 1.9972 - val_acc: 0.7190\n",
      "Epoch 129/150\n",
      "6982/6982 [==============================] - 0s 54us/step - loss: 0.6878 - acc: 0.7793 - val_loss: 1.9605 - val_acc: 0.7145\n",
      "Epoch 130/150\n",
      "6982/6982 [==============================] - 0s 54us/step - loss: 0.6825 - acc: 0.7879 - val_loss: 2.0037 - val_acc: 0.7125\n",
      "Epoch 131/150\n",
      "6982/6982 [==============================] - 0s 54us/step - loss: 0.6974 - acc: 0.7790 - val_loss: 2.0060 - val_acc: 0.7140\n",
      "Epoch 132/150\n",
      "6982/6982 [==============================] - 0s 55us/step - loss: 0.6907 - acc: 0.7760 - val_loss: 2.0168 - val_acc: 0.7170\n",
      "Epoch 133/150\n",
      "6982/6982 [==============================] - 0s 54us/step - loss: 0.6816 - acc: 0.7820 - val_loss: 2.0077 - val_acc: 0.7160\n",
      "Epoch 134/150\n",
      "6982/6982 [==============================] - 0s 54us/step - loss: 0.6786 - acc: 0.7839 - val_loss: 2.0596 - val_acc: 0.7165\n",
      "Epoch 135/150\n",
      "6982/6982 [==============================] - 0s 54us/step - loss: 0.6802 - acc: 0.7842 - val_loss: 2.0490 - val_acc: 0.7105\n",
      "Epoch 136/150\n",
      "6982/6982 [==============================] - 0s 55us/step - loss: 0.6704 - acc: 0.7860 - val_loss: 2.0037 - val_acc: 0.7120\n",
      "Epoch 137/150\n",
      "6982/6982 [==============================] - 0s 60us/step - loss: 0.6785 - acc: 0.7834 - val_loss: 2.0394 - val_acc: 0.7140\n",
      "Epoch 138/150\n",
      "6982/6982 [==============================] - 0s 59us/step - loss: 0.6705 - acc: 0.7852 - val_loss: 2.0632 - val_acc: 0.7165\n",
      "Epoch 139/150\n",
      "6982/6982 [==============================] - 0s 55us/step - loss: 0.6766 - acc: 0.7832 - val_loss: 2.0422 - val_acc: 0.7140\n",
      "Epoch 140/150\n",
      "6982/6982 [==============================] - 0s 57us/step - loss: 0.6628 - acc: 0.7892 - val_loss: 2.0381 - val_acc: 0.7170\n",
      "Epoch 141/150\n",
      "6982/6982 [==============================] - 0s 57us/step - loss: 0.6637 - acc: 0.7869 - val_loss: 2.1179 - val_acc: 0.7135\n",
      "Epoch 142/150\n",
      "6982/6982 [==============================] - 0s 58us/step - loss: 0.6777 - acc: 0.7822 - val_loss: 2.0836 - val_acc: 0.7150\n",
      "Epoch 143/150\n",
      "6982/6982 [==============================] - 0s 54us/step - loss: 0.6543 - acc: 0.7945 - val_loss: 2.0969 - val_acc: 0.7125\n",
      "Epoch 144/150\n",
      "6982/6982 [==============================] - 0s 62us/step - loss: 0.6688 - acc: 0.7846 - val_loss: 2.0933 - val_acc: 0.7145\n",
      "Epoch 145/150\n",
      "6982/6982 [==============================] - 0s 57us/step - loss: 0.6586 - acc: 0.7887 - val_loss: 2.1382 - val_acc: 0.7130\n",
      "Epoch 146/150\n",
      "6982/6982 [==============================] - 0s 57us/step - loss: 0.6584 - acc: 0.7883 - val_loss: 2.1225 - val_acc: 0.7075\n",
      "Epoch 147/150\n",
      "6982/6982 [==============================] - 0s 56us/step - loss: 0.6594 - acc: 0.7857 - val_loss: 2.1272 - val_acc: 0.7140\n",
      "Epoch 148/150\n",
      "6982/6982 [==============================] - 0s 58us/step - loss: 0.6691 - acc: 0.7859 - val_loss: 2.1253 - val_acc: 0.7075\n",
      "Epoch 149/150\n",
      "6982/6982 [==============================] - 0s 59us/step - loss: 0.6520 - acc: 0.7925 - val_loss: 2.1317 - val_acc: 0.7110\n",
      "Epoch 150/150\n",
      "6982/6982 [==============================] - 0s 58us/step - loss: 0.6563 - acc: 0.7893 - val_loss: 2.1536 - val_acc: 0.7095\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train_partial, y_train_partial,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=150,\n",
    "                    validation_data=(x_val, y_val),\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluacion del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2246/2246 [==============================] - 0s 21us/step\n",
      "Test loss score: 2.3630392160780813\n",
      "Test accuracy: 0.7034728406585972\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test,\n",
    "                       batch_size=batch_size, verbose=1)\n",
    "print('Test loss score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_dict = history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['val_loss', 'val_acc', 'loss', 'acc'])"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3.1342890110988395,\n",
       " 2.4028508804548574,\n",
       " 2.280016968974887,\n",
       " 2.1624674357919904,\n",
       " 2.0497156019300964,\n",
       " 1.970174854377456,\n",
       " 1.905318948574443,\n",
       " 1.862001951770023,\n",
       " 1.8291007211713044,\n",
       " 1.7906456535233362,\n",
       " 1.7560322307577383,\n",
       " 1.7179838048459055,\n",
       " 1.6825097266598508,\n",
       " 1.6521418256494658,\n",
       " 1.6248885422851116,\n",
       " 1.5922854171377032,\n",
       " 1.5653109858487473,\n",
       " 1.5414998245526097,\n",
       " 1.5303616870340868,\n",
       " 1.5075352570963465,\n",
       " 1.4948959828993886,\n",
       " 1.4699124049675973,\n",
       " 1.4519584210681833,\n",
       " 1.4158938010966187,\n",
       " 1.4022498194995838,\n",
       " 1.3673882043931929,\n",
       " 1.351057445719535,\n",
       " 1.3251266460369528,\n",
       " 1.3251213920864258,\n",
       " 1.3065721252114135,\n",
       " 1.2903972473502399,\n",
       " 1.263417149641834,\n",
       " 1.2560377897402852,\n",
       " 1.2328895588584972,\n",
       " 1.2143397875209143,\n",
       " 1.2060209890212346,\n",
       " 1.1968877449038375,\n",
       " 1.1898159195379008,\n",
       " 1.1736573200449838,\n",
       " 1.1438841475726063,\n",
       " 1.142193489329448,\n",
       " 1.1348644298661645,\n",
       " 1.1142362802495112,\n",
       " 1.1029821948023726,\n",
       " 1.0910698709328104,\n",
       " 1.0915027754298599,\n",
       " 1.0770559846347534,\n",
       " 1.0618778525314643,\n",
       " 1.0530569050210283,\n",
       " 1.049002801883668,\n",
       " 1.0493496468947494,\n",
       " 1.0373618845200683,\n",
       " 1.026025554813515,\n",
       " 1.0105545609224769,\n",
       " 0.9982052033762302,\n",
       " 0.9920803345707828,\n",
       " 0.9852845101942479,\n",
       " 0.9832115665065357,\n",
       " 0.9762584528653951,\n",
       " 0.9634873485606162,\n",
       " 0.9661473580893525,\n",
       " 0.9550252078222157,\n",
       " 0.9368374134605711,\n",
       " 0.9349124765915162,\n",
       " 0.9237483604628389,\n",
       " 0.9266722712807722,\n",
       " 0.9108216420725197,\n",
       " 0.9061309414721259,\n",
       " 0.9046054775446474,\n",
       " 0.8852450261140614,\n",
       " 0.8886896083977119,\n",
       " 0.8808218297977838,\n",
       " 0.8778474437954842,\n",
       " 0.8643086662916699,\n",
       " 0.8626904578954707,\n",
       " 0.8742649794922487,\n",
       " 0.8636804322856984,\n",
       " 0.8469885924899861,\n",
       " 0.8584063868575914,\n",
       " 0.8572052130553006,\n",
       " 0.840716674176918,\n",
       " 0.8321004935746479,\n",
       " 0.8166082793202724,\n",
       " 0.8127863239811745,\n",
       " 0.8279010323117709,\n",
       " 0.8244606439857625,\n",
       " 0.8154102494196918,\n",
       " 0.8192615335563369,\n",
       " 0.8093083140946363,\n",
       " 0.8100378266448997,\n",
       " 0.7960185301496797,\n",
       " 0.8067743064202336,\n",
       " 0.7895695397246707,\n",
       " 0.7894497433182709,\n",
       " 0.7820463902166258,\n",
       " 0.7870221457622072,\n",
       " 0.766268777568987,\n",
       " 0.7678047473742743,\n",
       " 0.7693253037103845,\n",
       " 0.7625620101864786,\n",
       " 0.7452352672892155,\n",
       " 0.7630409264557685,\n",
       " 0.7596551895278192,\n",
       " 0.7596138905988864,\n",
       " 0.7497141974100715,\n",
       " 0.7320611240362,\n",
       " 0.7397307154144404,\n",
       " 0.7353536242043449,\n",
       " 0.7429731888949991,\n",
       " 0.7467780763475986,\n",
       " 0.7147701513934566,\n",
       " 0.7200147366154949,\n",
       " 0.7165521978563649,\n",
       " 0.7248104412041432,\n",
       " 0.7290208920029712,\n",
       " 0.7146950880936858,\n",
       " 0.7198849829552475,\n",
       " 0.7135304081443387,\n",
       " 0.7244504603694146,\n",
       " 0.7055218467156479,\n",
       " 0.718964792828579,\n",
       " 0.6984464347925954,\n",
       " 0.711953394018931,\n",
       " 0.6878595703210233,\n",
       " 0.6954186832928719,\n",
       " 0.7072452470399834,\n",
       " 0.6919065335270874,\n",
       " 0.6812035917245498,\n",
       " 0.6877633836371139,\n",
       " 0.6825093228644199,\n",
       " 0.6973648391742995,\n",
       " 0.6907184659768845,\n",
       " 0.6815842324497023,\n",
       " 0.6785944674971861,\n",
       " 0.6801566557227217,\n",
       " 0.670422827487209,\n",
       " 0.6784894535655758,\n",
       " 0.670528737326059,\n",
       " 0.6765568436848267,\n",
       " 0.6628219384205987,\n",
       " 0.6637134581454263,\n",
       " 0.6776707577715201,\n",
       " 0.6543316739365624,\n",
       " 0.6687873497677888,\n",
       " 0.6586193558958737,\n",
       " 0.6583873704438632,\n",
       " 0.6593871861824296,\n",
       " 0.669115928943162,\n",
       " 0.6519584151913805,\n",
       " 0.6562783898749962]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_dict['loss']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gráficas del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "# \"bo\" is for \"blue dot\"\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "# b is for \"solid blue line\"\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.clf()   # clear figure\n",
    "acc_values = history_dict['acc']\n",
    "val_acc_values = history_dict['val_acc']\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusiones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A la vista de los resultados, el modelo empieza a caer en el overfitting a partir de los 40 epochs. En dicho valor el accuracy deja de crecer y las pérdidas se incrementan.\n",
    "El modelo propuesto obtiene un 0,7 de accuracy por lo que se puede considerar válido de cara a lo requerido en la práctica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Trabajo 3",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
